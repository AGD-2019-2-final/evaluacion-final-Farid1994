{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
      "    AS (lett:CHARARRAY,\n",
      "        longtext:BAG{t:(p:CHARARRAY)},\n",
      "        strin:map[]);\n",
      " t1= FOREACH u GENERATE FLATTEN($1), FLATTEN($2);\n",
      " t2= FOREACH t1 GENERATE $0, $1;\n",
      " t3= GROUP t2 BY ($0, $1);\n",
      " result= FOREACH t3 GENERATE $0, COUNT(t2);\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
    "    AS (lett:CHARARRAY,\n",
    "        longtext:BAG{t:(p:CHARARRAY)},\n",
    "        strin:map[]);\n",
    "t1= FOREACH u GENERATE FLATTEN($1), FLATTEN($2);\n",
    "t2= FOREACH t1 GENERATE $0, $1;\n",
    "t3= GROUP t2 BY ($0, $1);\n",
    "result= FOREACH t3 GENERATE $0, COUNT(t2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DUMP result;\n",
      "2020-02-15 17:07:40,394 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:40,484 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:40,496 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:07:40,544 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:07:40,546 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:07:40,576 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local119216425_0003\n",
      "2020-02-15 17:07:40,716 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786460600/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:07:40,722 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786460600/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:07:40,722 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786460600/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:07:40,722 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-820330349/tmp-1720926191/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581786460600/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:07:40,724 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786460601/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:07:41,224 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786460601/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:07:41,225 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786460601/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:07:41,225 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-820330349/tmp698805174/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581786460601/automaton-1.11-8.jar\n",
      "2020-02-15 17:07:41,226 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786460602/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:07:41,237 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786460602/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:07:41,237 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786460602/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:07:41,238 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-820330349/tmp594398497/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581786460602/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:07:41,239 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786460603/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:07:41,244 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786460603/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:07:41,244 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786460603/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:07:41,244 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-820330349/tmp1374881581/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581786460603/joda-time-2.9.3.jar\n",
      "2020-02-15 17:07:41,282 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786460600/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:07:41,283 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786460601/automaton-1.11-8.jar\n",
      "2020-02-15 17:07:41,283 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786460602/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:07:41,283 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786460603/joda-time-2.9.3.jar\n",
      "2020-02-15 17:07:41,283 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:07:41,284 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:07:41,304 [Thread-81] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:07:41,304 [Thread-81] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:07:41,305 [Thread-81] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:07:41,305 [Thread-81] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:07:41,305 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:07:41,309 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:07:41,309 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local119216425_0003_m_000000_0\n",
      "2020-02-15 17:07:41,340 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:07:41,340 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:07:41,340 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:07:41,346 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:07:41,383 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 17:07:41,383 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 17:07:41,383 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 17:07:41,384 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 17:07:41,384 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 17:07:41,389 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 17:07:41,451 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:07:41,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 17:07:41,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 17:07:41,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 9000; bufvoid = 104857600\n",
      "2020-02-15 17:07:41,452 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212400(104849600); length = 1997/6553600\n",
      "2020-02-15 17:07:41,506 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 17:07:41,509 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local119216425_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:07:41,517 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:07:41,517 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local119216425_0003_m_000000_0' done.\n",
      "2020-02-15 17:07:41,517 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local119216425_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17424840\n",
      "\t\tFILE: Number of bytes written=36236572\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=500\n",
      "\t\tMap output bytes=9000\n",
      "\t\tMap output materialized bytes=1476\n",
      "\t\tInput split bytes=402\n",
      "\t\tCombine input records=500\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=10\n",
      "\t\tTotal committed heap usage (bytes)=395313152\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 17:07:41,518 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local119216425_0003_m_000000_0\n",
      "2020-02-15 17:07:41,518 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:07:41,523 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 17:07:41,527 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local119216425_0003_r_000000_0\n",
      "2020-02-15 17:07:41,550 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:07:41,550 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:07:41,552 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:07:41,555 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@66893218\n",
      "2020-02-15 17:07:41,569 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 17:07:41,576 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local119216425_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 17:07:41,614 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local119216425_0003_m_000000_0 decomp: 1472 len: 1476 to MEMORY\n",
      "2020-02-15 17:07:41,618 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1472 bytes from map-output for attempt_local119216425_0003_m_000000_0\n",
      "2020-02-15 17:07:41,620 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1472, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1472\n",
      "2020-02-15 17:07:41,623 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 17:07:41,625 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:07:41,625 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 17:07:41,632 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:07:41,632 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1457 bytes\n",
      "2020-02-15 17:07:41,636 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1472 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 17:07:41,636 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1476 bytes from disk\n",
      "2020-02-15 17:07:41,637 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 17:07:41,637 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:07:41,637 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1457 bytes\n",
      "2020-02-15 17:07:41,638 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:07:41,651 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:07:41,651 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:07:41,652 [pool-8-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-15 17:07:41,664 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local119216425_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:07:41,667 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:07:41,667 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local119216425_0003_r_000000_0 is allowed to commit now\n",
      "2020-02-15 17:07:41,669 [pool-8-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local119216425_0003_r_000000_0' to file:/tmp/temp-820330349/tmp1256587747/_temporary/0/task_local119216425_0003_r_000000\n",
      "2020-02-15 17:07:41,671 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 17:07:41,671 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local119216425_0003_r_000000_0' done.\n",
      "2020-02-15 17:07:41,671 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local119216425_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17427824\n",
      "\t\tFILE: Number of bytes written=36239258\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=70\n",
      "\t\tReduce shuffle bytes=1476\n",
      "\t\tReduce input records=70\n",
      "\t\tReduce output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=395313152\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:07:41,671 [pool-8-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local119216425_0003_r_000000_0\n",
      "2020-02-15 17:07:41,671 [Thread-81] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 17:07:46,344 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,345 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,345 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,356 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,356 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,357 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:07:46,369 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "((a,aaa),5)\n",
      "((a,bbb),7)\n",
      "((a,ccc),13)\n",
      "((a,ddd),13)\n",
      "((a,eee),7)\n",
      "((a,fff),10)\n",
      "((a,ggg),8)\n",
      "((a,hhh),8)\n",
      "((a,iii),7)\n",
      "((a,jjj),10)\n",
      "((b,aaa),4)\n",
      "((b,bbb),7)\n",
      "((b,ccc),5)\n",
      "((b,ddd),7)\n",
      "((b,eee),5)\n",
      "((b,fff),8)\n",
      "((b,ggg),4)\n",
      "((b,hhh),7)\n",
      "((b,iii),7)\n",
      "((b,jjj),5)\n",
      "((c,aaa),5)\n",
      "((c,bbb),4)\n",
      "((c,ccc),12)\n",
      "((c,ddd),9)\n",
      "((c,eee),6)\n",
      "((c,fff),8)\n",
      "((c,ggg),7)\n",
      "((c,hhh),7)\n",
      "((c,iii),8)\n",
      "((c,jjj),8)\n",
      "((d,aaa),4)\n",
      "((d,bbb),6)\n",
      "((d,ccc),7)\n",
      "((d,ddd),5)\n",
      "((d,eee),6)\n",
      "((d,fff),8)\n",
      "((d,ggg),6)\n",
      "((d,hhh),4)\n",
      "((d,iii),9)\n",
      "((d,jjj),8)\n",
      "((e,aaa),3)\n",
      "((e,bbb),8)\n",
      "((e,ccc),9)\n",
      "((e,ddd),7)\n",
      "((e,eee),7)\n",
      "((e,fff),9)\n",
      "((e,ggg),4)\n",
      "((e,hhh),4)\n",
      "((e,iii),8)\n",
      "((e,jjj),3)\n",
      "((f,aaa),8)\n",
      "((f,bbb),10)\n",
      "((f,ccc),13)\n",
      "((f,ddd),17)\n",
      "((f,eee),11)\n",
      "((f,fff),11)\n",
      "((f,ggg),9)\n",
      "((f,hhh),10)\n",
      "((f,iii),10)\n",
      "((f,jjj),12)\n",
      "((g,aaa),3)\n",
      "((g,bbb),3)\n",
      "((g,ccc),6)\n",
      "((g,ddd),5)\n",
      "((g,eee),4)\n",
      "((g,fff),5)\n",
      "((g,ggg),4)\n",
      "((g,hhh),3)\n",
      "((g,iii),4)\n",
      "((g,jjj),6)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "DUMP result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-15 17:09:15,123 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-15 17:09:16,341 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-15 17:09:16,725 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-02-15 17:09:16,727 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-02-15 17:09:16,764 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:09:16,769 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-15 17:09:16,788 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:09:16,800 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-15 17:09:17,054 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-15 17:09:17,070 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:17,096 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-15 17:09:17,192 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:09:17,319 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:09:17,352 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:09:17,509 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1876818304_0001\n",
      "2020-02-15 17:09:17,879 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786557622/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:09:17,908 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786557622/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:09:17,909 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786557622/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:09:17,909 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-194660622/tmp-1792186151/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581786557622/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:09:17,910 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786557623/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:09:17,915 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786557623/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:09:17,916 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786557623/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:09:17,916 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-194660622/tmp268264746/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581786557623/automaton-1.11-8.jar\n",
      "2020-02-15 17:09:17,917 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786557624/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:09:17,922 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786557624/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:09:17,922 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786557624/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:09:17,922 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-194660622/tmp1890957682/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581786557624/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:09:17,924 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581786557625/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:09:17,933 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581786557625/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:09:17,933 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581786557625/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:09:17,933 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-194660622/tmp1447740523/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581786557625/joda-time-2.9.3.jar\n",
      "2020-02-15 17:09:18,047 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786557622/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:09:18,048 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786557623/automaton-1.11-8.jar\n",
      "2020-02-15 17:09:18,048 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786557624/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:09:18,048 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581786557625/joda-time-2.9.3.jar\n",
      "2020-02-15 17:09:18,054 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:09:18,056 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:09:18,130 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-15 17:09:18,132 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:09:18,133 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:09:18,134 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:09:18,134 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:09:18,135 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:09:18,241 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:09:18,242 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1876818304_0001_m_000000_0\n",
      "2020-02-15 17:09:18,325 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:09:18,326 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:09:18,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:09:18,361 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:09:18,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 17:09:18,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 17:09:18,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 17:09:18,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 17:09:18,424 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 17:09:18,431 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 17:09:18,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:09:18,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 17:09:18,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 17:09:18,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 9000; bufvoid = 104857600\n",
      "2020-02-15 17:09:18,575 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26212400(104849600); length = 1997/6553600\n",
      "2020-02-15 17:09:18,666 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 17:09:18,670 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1876818304_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:09:18,683 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:09:18,683 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1876818304_0001_m_000000_0' done.\n",
      "2020-02-15 17:09:18,691 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1876818304_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803064\n",
      "\t\tFILE: Number of bytes written=12099826\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=500\n",
      "\t\tMap output bytes=9000\n",
      "\t\tMap output materialized bytes=1476\n",
      "\t\tInput split bytes=402\n",
      "\t\tCombine input records=500\n",
      "\t\tCombine output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=284688384\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 17:09:18,691 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1876818304_0001_m_000000_0\n",
      "2020-02-15 17:09:18,692 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:09:18,695 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 17:09:18,695 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1876818304_0001_r_000000_0\n",
      "2020-02-15 17:09:18,726 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:09:18,726 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:09:18,733 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:09:18,737 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5da2c2ec\n",
      "2020-02-15 17:09:18,764 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 17:09:18,770 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1876818304_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 17:09:18,844 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1876818304_0001_m_000000_0 decomp: 1472 len: 1476 to MEMORY\n",
      "2020-02-15 17:09:18,848 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1472 bytes from map-output for attempt_local1876818304_0001_m_000000_0\n",
      "2020-02-15 17:09:18,854 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1472, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1472\n",
      "2020-02-15 17:09:18,856 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 17:09:18,858 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:09:18,858 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 17:09:18,866 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:09:18,866 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1457 bytes\n",
      "2020-02-15 17:09:18,870 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1472 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 17:09:18,871 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1476 bytes from disk\n",
      "2020-02-15 17:09:18,872 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 17:09:18,872 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:09:18,872 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1457 bytes\n",
      "2020-02-15 17:09:18,873 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:09:18,885 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:09:18,885 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:09:18,969 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-15 17:09:19,007 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1876818304_0001_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:09:19,030 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:09:19,030 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1876818304_0001_r_000000_0 is allowed to commit now\n",
      "2020-02-15 17:09:19,073 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1876818304_0001_r_000000_0' to file:/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q08-10/output/_temporary/0/task_local1876818304_0001_r_000000\n",
      "2020-02-15 17:09:19,076 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 17:09:19,076 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1876818304_0001_r_000000_0' done.\n",
      "2020-02-15 17:09:19,077 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1876818304_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5806048\n",
      "\t\tFILE: Number of bytes written=12102031\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=70\n",
      "\t\tReduce shuffle bytes=1476\n",
      "\t\tReduce input records=70\n",
      "\t\tReduce output records=70\n",
      "\t\tSpilled Records=70\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=284688384\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:09:19,077 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1876818304_0001_r_000000_0\n",
      "2020-02-15 17:09:19,078 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 17:09:23,100 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:23,116 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:23,116 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-02-15 17:09:23,118 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:23,149 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:23,150 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:09:23,151 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
