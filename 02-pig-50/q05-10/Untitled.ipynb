{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
      "    AS (id:CHARARRAY,\n",
      "        date:CHARARRAY,\n",
      "        num:CHARARRAY);\n",
      " u2= FOREACH u GENERATE FLATTEN($1);\n",
      " DUMP u2;\n",
      "2020-02-14 00:17:23,089 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:23,135 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:23,141 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-14 00:17:23,178 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-14 00:17:23,180 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-14 00:17:23,189 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local831835529_0002\n",
      "2020-02-14 00:17:23,279 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581639443213/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-14 00:17:23,284 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581639443213/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-14 00:17:23,284 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581639443213/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-14 00:17:23,284 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1931926343/tmp1281158025/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581639443213/pig-0.17.0-core-h2.jar\n",
      "2020-02-14 00:17:23,285 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581639443214/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar\n",
      "2020-02-14 00:17:23,288 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581639443214/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-14 00:17:23,288 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581639443214/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar\n",
      "2020-02-14 00:17:23,288 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1931926343/tmp-500812847/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581639443214/automaton-1.11-8.jar\n",
      "2020-02-14 00:17:23,289 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581639443215/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar\n",
      "2020-02-14 00:17:23,293 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581639443215/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-14 00:17:23,293 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581639443215/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar\n",
      "2020-02-14 00:17:23,293 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1931926343/tmp-1261403315/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581639443215/antlr-runtime-3.4.jar\n",
      "2020-02-14 00:17:23,294 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581639443216/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar\n",
      "2020-02-14 00:17:23,299 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581639443216/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-14 00:17:23,299 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581639443216/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar\n",
      "2020-02-14 00:17:23,299 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1931926343/tmp1721760586/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581639443216/joda-time-2.9.3.jar\n",
      "2020-02-14 00:17:23,334 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581639443213/pig-0.17.0-core-h2.jar\n",
      "2020-02-14 00:17:23,334 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581639443214/automaton-1.11-8.jar\n",
      "2020-02-14 00:17:23,334 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581639443215/antlr-runtime-3.4.jar\n",
      "2020-02-14 00:17:23,335 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581639443216/joda-time-2.9.3.jar\n",
      "2020-02-14 00:17:23,335 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-14 00:17:23,336 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-14 00:17:23,347 [Thread-49] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-14 00:17:23,347 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-14 00:17:23,347 [Thread-49] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-14 00:17:23,347 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-14 00:17:23,351 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-14 00:17:23,351 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local831835529_0002_m_000000_0\n",
      "2020-02-14 00:17:23,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-14 00:17:23,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-14 00:17:23,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-14 00:17:23,377 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-14 00:17:23,387 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-14 00:17:23,387 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-14 00:17:23,414 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-14 00:17:23,414 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local831835529_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-14 00:17:23,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-14 00:17:23,418 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local831835529_0002_m_000000_0 is allowed to commit now\n",
      "2020-02-14 00:17:23,421 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local831835529_0002_m_000000_0' to file:/tmp/temp1931926343/tmp70615718/_temporary/0/task_local831835529_0002_m_000000\n",
      "2020-02-14 00:17:23,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-14 00:17:23,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local831835529_0002_m_000000_0' done.\n",
      "2020-02-14 00:17:23,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local831835529_0002_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11606920\n",
      "\t\tFILE: Number of bytes written=24124951\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tInput split bytes=402\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=273678336\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-14 00:17:23,422 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local831835529_0002_m_000000_0\n",
      "2020-02-14 00:17:23,422 [Thread-49] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-14 00:17:28,711 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,712 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,713 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,716 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,717 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,717 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-14 00:17:28,730 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "({(b),(g),(f)})\n",
      "({(a),(f),(c)})\n",
      "({(f),(e),(a),(c)})\n",
      "({(a),(b)})\n",
      "({(f),(g),(d),(a)})\n",
      "({(c),(d)})\n",
      "({(g),(d),(a)})\n",
      "({(b),(a)})\n",
      "({(d),(e),(a),(f)})\n",
      "({(d),(b),(g),(f)})\n",
      "({(d),(c),(f),(b)})\n",
      "({(d),(e),(a),(c)})\n",
      "({(g),(e),(f),(b)})\n",
      "({(c),(f)})\n",
      "({(d),(b)})\n",
      "({(f),(e)})\n",
      "({(e),(b),(f)})\n",
      "({(g),(a)})\n",
      "({(e),(c),(f),(a)})\n",
      "({(e),(a)})\n",
      "({(e),(f)})\n",
      "({(c),(b),(g)})\n",
      "({(c),(f),(a)})\n",
      "({(f),(a),(d)})\n",
      "({(c),(d)})\n",
      "({(e),(d),(c)})\n",
      "({(a),(e),(f)})\n",
      "({(c),(a),(g)})\n",
      "({(f),(e)})\n",
      "({(f),(c),(a),(g)})\n",
      "({(b),(f)})\n",
      "({(b),(f)})\n",
      "({(a),(c)})\n",
      "({(b),(f),(c)})\n",
      "({(f),(a),(e)})\n",
      "({(a),(f)})\n",
      "({(c),(a)})\n",
      "({(c),(a),(e),(f)})\n",
      "({(e),(d)})\n",
      "({(f),(a),(d)})\n"
     ]
    }
   ],
   "source": [
    "%%pig \n",
    "u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
    "    AS (id:CHARARRAY,\n",
    "        date:CHARARRAY,\n",
    "        num:CHARARRAY);\n",
    "u2= FOREACH u GENERATE FLATTEN($1);\n",
    "DUMP u2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
      "    AS (lett:CHARARRAY,\n",
      "        longtext:BAG{t:(p:CHARARRAY)},\n",
      "        strin:CHARARRAY);\n",
      " u2= FOREACH u GENERATE FLATTEN($1);\n",
      " u3= GROUP u2 by $0;\n",
      " DUMP u3;\n",
      "2020-02-15 16:05:23,580 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:23,617 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:23,621 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 16:05:23,660 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 16:05:23,663 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 16:05:23,679 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1048337367_0004\n",
      "2020-02-15 16:05:23,829 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581782723703/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 16:05:23,835 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581782723703/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 16:05:23,835 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581782723703/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 16:05:23,835 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1388471897/tmp866327336/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581782723703/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 16:05:23,836 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581782723704/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar\n",
      "2020-02-15 16:05:23,842 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581782723704/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 16:05:23,842 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581782723704/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/automaton-1.11-8.jar\n",
      "2020-02-15 16:05:23,842 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1388471897/tmp-50270488/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581782723704/automaton-1.11-8.jar\n",
      "2020-02-15 16:05:23,843 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581782723705/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 16:05:23,849 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581782723705/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 16:05:23,849 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581782723705/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 16:05:23,849 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1388471897/tmp1009561507/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581782723705/antlr-runtime-3.4.jar\n",
      "2020-02-15 16:05:23,851 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581782723706/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar\n",
      "2020-02-15 16:05:23,857 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581782723706/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 16:05:23,857 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581782723706/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q05-10/joda-time-2.9.3.jar\n",
      "2020-02-15 16:05:23,857 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-1388471897/tmp2065473430/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581782723706/joda-time-2.9.3.jar\n",
      "2020-02-15 16:05:23,895 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581782723703/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 16:05:23,895 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581782723704/automaton-1.11-8.jar\n",
      "2020-02-15 16:05:23,895 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581782723705/antlr-runtime-3.4.jar\n",
      "2020-02-15 16:05:23,895 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581782723706/joda-time-2.9.3.jar\n",
      "2020-02-15 16:05:23,896 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 16:05:23,897 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 16:05:23,906 [Thread-119] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 16:05:23,906 [Thread-119] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 16:05:23,906 [Thread-119] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 16:05:23,906 [Thread-119] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 16:05:23,907 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 16:05:23,912 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 16:05:23,912 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1048337367_0004_m_000000_0\n",
      "2020-02-15 16:05:23,926 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 16:05:23,926 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 16:05:23,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 16:05:23,929 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 16:05:24,019 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 16:05:24,019 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 16:05:24,019 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 16:05:24,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 16:05:24,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 16:05:24,020 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 16:05:24,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 16:05:24,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 16:05:24,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 16:05:24,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 791; bufvoid = 104857600\n",
      "2020-02-15 16:05:24,066 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26213948(104855792); length = 449/6553600\n",
      "2020-02-15 16:05:24,070 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 16:05:24,071 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1048337367_0004_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 16:05:24,074 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 16:05:24,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1048337367_0004_m_000000_0' done.\n",
      "2020-02-15 16:05:24,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1048337367_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23218507\n",
      "\t\tFILE: Number of bytes written=48277560\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=113\n",
      "\t\tMap output bytes=791\n",
      "\t\tMap output materialized bytes=1023\n",
      "\t\tInput split bytes=402\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=113\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=385875968\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 16:05:24,075 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1048337367_0004_m_000000_0\n",
      "2020-02-15 16:05:24,075 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 16:05:24,076 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 16:05:24,077 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1048337367_0004_r_000000_0\n",
      "2020-02-15 16:05:24,105 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 16:05:24,105 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 16:05:24,106 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 16:05:24,106 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e26ef84\n",
      "2020-02-15 16:05:24,107 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 16:05:24,123 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1048337367_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 16:05:24,124 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1048337367_0004_m_000000_0 decomp: 1019 len: 1023 to MEMORY\n",
      "2020-02-15 16:05:24,127 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1019 bytes from map-output for attempt_local1048337367_0004_m_000000_0\n",
      "2020-02-15 16:05:24,128 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1019, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1019\n",
      "2020-02-15 16:05:24,129 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 16:05:24,130 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 16:05:24,130 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 16:05:24,131 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 16:05:24,131 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1013 bytes\n",
      "2020-02-15 16:05:24,136 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1019 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 16:05:24,137 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1023 bytes from disk\n",
      "2020-02-15 16:05:24,137 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 16:05:24,137 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 16:05:24,138 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1013 bytes\n",
      "2020-02-15 16:05:24,139 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 16:05:24,140 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 16:05:24,141 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 16:05:24,153 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-02-15 16:05:24,163 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1048337367_0004_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 16:05:24,172 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 16:05:24,172 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1048337367_0004_r_000000_0 is allowed to commit now\n",
      "2020-02-15 16:05:24,174 [pool-13-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1048337367_0004_r_000000_0' to file:/tmp/temp-1388471897/tmp227462075/_temporary/0/task_local1048337367_0004_r_000000\n",
      "2020-02-15 16:05:24,180 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 16:05:24,181 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1048337367_0004_r_000000_0' done.\n",
      "2020-02-15 16:05:24,182 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1048337367_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23220585\n",
      "\t\tFILE: Number of bytes written=48279234\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=7\n",
      "\t\tReduce shuffle bytes=1023\n",
      "\t\tReduce input records=113\n",
      "\t\tReduce output records=7\n",
      "\t\tSpilled Records=113\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=385875968\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 16:05:24,182 [pool-13-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1048337367_0004_r_000000_0\n",
      "2020-02-15 16:05:24,182 [Thread-119] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 16:05:29,287 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,288 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,289 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,302 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,303 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,304 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 16:05:29,315 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(a,{(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a),(a)})\n",
      "(b,{(b),(b),(b),(b),(b),(b),(b),(b),(b),(b),(b),(b)})\n",
      "(c,{(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c),(c)})\n",
      "(d,{(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d),(d)})\n",
      "(e,{(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e),(e)})\n",
      "(f,{(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f),(f)})\n",
      "(g,{(g),(g),(g),(g),(g),(g),(g),(g),(g)})\n"
     ]
    }
   ],
   "source": [
    "%%pig \n",
    "u = LOAD 'data.tsv' USING PigStorage('\\t')\n",
    "    AS (lett:CHARARRAY,\n",
    "        longtext:BAG{t:(p:CHARARRAY)},\n",
    "        strin:CHARARRAY);\n",
    "u2= FOREACH u GENERATE FLATTEN($1);\n",
    "u3= GROUP u2 by $0;\n",
    "DUMP u3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
