{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " u = LOAD 'data.csv' USING PigStorage(',') \n",
      "    AS (id:int, \n",
      "        firstname:CHARARRAY, \n",
      "        surname:CHARARRAY, \n",
      "        birthday:CHARARRAY, \n",
      "        color:CHARARRAY, \n",
      "        quantity:INT);\n",
      " t1= FOREACH u GENERATE $2, (int)SIZE($2);\n",
      " t2= ORDER t1 BY $1 DESC, $0;\n",
      " result = LIMIT t2 5;\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "u = LOAD 'data.csv' USING PigStorage(',') \n",
    "    AS (id:int, \n",
    "        firstname:CHARARRAY, \n",
    "        surname:CHARARRAY, \n",
    "        birthday:CHARARRAY, \n",
    "        color:CHARARRAY, \n",
    "        quantity:INT);\n",
    "t1= FOREACH u GENERATE $2, (int)SIZE($2);\n",
    "t2= ORDER t1 BY $1 DESC, $0;\n",
    "result = LIMIT t2 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-15 17:55:30,661 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-15 17:55:32,212 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-15 17:55:32,743 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-02-15 17:55:32,744 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-02-15 17:55:32,793 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:55:32,799 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-15 17:55:32,818 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-15 17:55:33,015 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-15 17:55:33,041 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:33,063 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-15 17:55:33,131 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:55:33,237 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:55:33,272 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:55:33,433 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local81396577_0001\n",
      "2020-02-15 17:55:34,293 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789333559/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:34,330 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789333559/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:34,331 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789333559/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:34,331 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp-1923797500/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581789333559/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:34,366 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789333560/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:34,382 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789333560/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:34,382 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789333560/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:34,382 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1853301813/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581789333560/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:34,385 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789333561/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:34,396 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789333561/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:34,396 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789333561/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:34,396 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1975744313/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581789333561/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:34,397 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789333562/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:34,403 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789333562/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:34,403 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789333562/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:34,403 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1337183767/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581789333562/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:34,513 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789333559/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:34,514 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789333560/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:34,514 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789333561/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:34,514 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789333562/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:34,520 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:55:34,525 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:55:34,597 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:55:34,601 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:34,602 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:34,602 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:55:34,726 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:55:34,727 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local81396577_0001_m_000000_0\n",
      "2020-02-15 17:55:34,808 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:34,809 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:34,846 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:34,853 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 632\n",
      "Input split[0]:\n",
      "   Length = 632\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:55:34,878 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:34,878 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:34,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:55:34,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local81396577_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:34,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:55:34,963 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local81396577_0001_m_000000_0 is allowed to commit now\n",
      "2020-02-15 17:55:34,969 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local81396577_0001_m_000000_0' to file:/tmp/temp1243895233/tmp1527058485/_temporary/0/task_local81396577_0001_m_000000\n",
      "2020-02-15 17:55:34,971 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:55:34,972 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local81396577_0001_m_000000_0' done.\n",
      "2020-02-15 17:55:34,976 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local81396577_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801916\n",
      "\t\tFILE: Number of bytes written=12063635\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tInput split bytes=402\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=400031744\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:55:34,977 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local81396577_0001_m_000000_0\n",
      "2020-02-15 17:55:34,977 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:55:39,578 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:39,595 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:39,595 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-02-15 17:55:39,595 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:55:39,598 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:39,759 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:39,768 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:55:39,837 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:55:39,840 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:55:39,874 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local24183939_0002\n",
      "2020-02-15 17:55:40,035 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789339922/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:40,040 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789339922/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:40,040 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789339922/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:40,040 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1202959715/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581789339922/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:40,042 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789339923/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:40,047 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789339923/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:40,048 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789339923/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:40,048 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp658796972/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581789339923/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:40,050 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789339924/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:40,057 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789339924/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:40,057 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789339924/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:40,057 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp-859738899/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581789339924/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:40,058 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789339925/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:40,066 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789339925/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:40,067 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789339925/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:40,067 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1299207516/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581789339925/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:40,206 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789339922/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:40,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789339923/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:40,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789339924/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:40,207 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789339925/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:40,219 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:55:40,219 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:55:40,244 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:55:40,245 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:55:40,245 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:40,245 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:40,246 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:55:40,257 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:55:40,257 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local24183939_0002_m_000000_0\n",
      "2020-02-15 17:55:40,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:40,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:40,293 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:40,302 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 259\n",
      "Input split[0]:\n",
      "   Length = 259\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:55:40,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 17:55:40,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 17:55:40,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 17:55:40,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 17:55:40,487 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 17:55:40,499 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 17:55:40,540 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:55:40,540 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 17:55:40,540 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 17:55:40,540 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 608; bufvoid = 104857600\n",
      "2020-02-15 17:55:40,540 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-02-15 17:55:40,554 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 17:55:40,559 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local24183939_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:40,565 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:55:40,565 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local24183939_0002_m_000000_0' done.\n",
      "2020-02-15 17:55:40,566 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local24183939_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603451\n",
      "\t\tFILE: Number of bytes written=24144489\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=608\n",
      "\t\tMap output materialized bytes=650\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=400031744\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 17:55:40,567 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local24183939_0002_m_000000_0\n",
      "2020-02-15 17:55:40,567 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:55:40,571 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 17:55:40,571 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local24183939_0002_r_000000_0\n",
      "2020-02-15 17:55:40,602 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:40,602 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:40,606 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:40,610 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@15074bb9\n",
      "2020-02-15 17:55:40,633 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 17:55:40,643 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local24183939_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 17:55:40,734 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local24183939_0002_m_000000_0 decomp: 646 len: 650 to MEMORY\n",
      "2020-02-15 17:55:40,741 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 646 bytes from map-output for attempt_local24183939_0002_m_000000_0\n",
      "2020-02-15 17:55:40,743 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 646, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->646\n",
      "2020-02-15 17:55:40,747 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 17:55:40,749 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:40,750 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 17:55:40,762 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:40,763 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 621 bytes\n",
      "2020-02-15 17:55:40,764 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 646 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 17:55:40,765 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 650 bytes from disk\n",
      "2020-02-15 17:55:40,765 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 17:55:40,765 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:40,769 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 621 bytes\n",
      "2020-02-15 17:55:40,770 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:40,782 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:40,782 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:40,783 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-15 17:55:40,817 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local24183939_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:40,823 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:40,823 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local24183939_0002_r_000000_0 is allowed to commit now\n",
      "2020-02-15 17:55:40,827 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local24183939_0002_r_000000_0' to file:/tmp/temp1243895233/tmp1821239701/_temporary/0/task_local24183939_0002_r_000000\n",
      "2020-02-15 17:55:40,828 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 17:55:40,828 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local24183939_0002_r_000000_0' done.\n",
      "2020-02-15 17:55:40,829 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local24183939_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604783\n",
      "\t\tFILE: Number of bytes written=24145207\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=650\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=400031744\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:55:40,830 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local24183939_0002_r_000000_0\n",
      "2020-02-15 17:55:40,830 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 17:55:45,278 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:45,279 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:45,280 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:45,405 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:45,419 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:55:45,478 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:55:45,481 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:55:45,500 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1018724977_0003\n",
      "2020-02-15 17:55:45,657 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789345547/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:45,664 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789345547/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:45,664 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789345547/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:45,664 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp-1165309034/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581789345547/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:45,666 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789345548/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:45,672 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789345548/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:45,672 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789345548/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:45,673 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1931894559/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581789345548/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:45,674 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789345549/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:45,681 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789345549/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:45,681 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789345549/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:45,681 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1909077548/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581789345549/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:45,683 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789345550/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:45,694 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789345550/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:45,694 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789345550/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:45,694 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1650651730/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581789345550/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:45,696 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789345551/tmp1821239701 <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pigsample_1651795723_1581789345348\n",
      "2020-02-15 17:55:45,702 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789345551/tmp1821239701 /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pigsample_1651795723_1581789345348' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pigsample_1651795723_1581789345348': Protocol error\n",
      "\n",
      "2020-02-15 17:55:45,702 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789345551/tmp1821239701 <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pigsample_1651795723_1581789345348\n",
      "2020-02-15 17:55:45,707 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp1821239701 as file:/tmp/hadoop-root/mapred/local/1581789345551/tmp1821239701\n",
      "2020-02-15 17:55:45,764 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789345547/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:45,765 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789345548/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:45,765 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789345549/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:45,765 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789345550/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:45,765 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:55:45,765 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:55:45,777 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:55:45,778 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:55:45,778 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:45,778 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:45,778 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:55:45,784 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:55:45,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1018724977_0003_m_000000_0\n",
      "2020-02-15 17:55:45,809 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:45,810 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:45,810 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:45,815 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 259\n",
      "Input split[0]:\n",
      "   Length = 259\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:55:45,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 17:55:45,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 17:55:45,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 17:55:45,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 17:55:45,886 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 17:55:45,890 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 17:55:45,897 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:55:45,898 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 17:55:45,898 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 17:55:45,898 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 295; bufvoid = 104857600\n",
      "2020-02-15 17:55:45,898 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-02-15 17:55:45,923 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 17:55:45,925 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1018724977_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:45,930 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:55:45,930 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1018724977_0003_m_000000_0' done.\n",
      "2020-02-15 17:55:45,932 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1018724977_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406402\n",
      "\t\tFILE: Number of bytes written=36236347\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=295\n",
      "\t\tMap output materialized bytes=105\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=18\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=394264576\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 17:55:45,932 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1018724977_0003_m_000000_0\n",
      "2020-02-15 17:55:45,933 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:55:45,934 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 17:55:45,934 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1018724977_0003_r_000000_0\n",
      "2020-02-15 17:55:45,951 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:45,951 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:45,955 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:45,956 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@450c6b7c\n",
      "2020-02-15 17:55:45,959 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 17:55:45,963 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1018724977_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 17:55:45,968 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1018724977_0003_m_000000_0 decomp: 101 len: 105 to MEMORY\n",
      "2020-02-15 17:55:45,975 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 101 bytes from map-output for attempt_local1018724977_0003_m_000000_0\n",
      "2020-02-15 17:55:45,976 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->101\n",
      "2020-02-15 17:55:45,981 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-02-15 17:55:45,983 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 17:55:45,986 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:45,986 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 17:55:45,988 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:45,989 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-15 17:55:45,991 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 101 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 17:55:45,992 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 105 bytes from disk\n",
      "2020-02-15 17:55:45,992 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 17:55:45,992 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:45,993 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-15 17:55:45,993 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:45,996 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:45,996 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:46,002 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1018724977_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:46,005 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:46,005 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1018724977_0003_r_000000_0 is allowed to commit now\n",
      "2020-02-15 17:55:46,009 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1018724977_0003_r_000000_0' to file:/tmp/temp1243895233/tmp-171471980/_temporary/0/task_local1018724977_0003_r_000000\n",
      "2020-02-15 17:55:46,010 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 17:55:46,011 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1018724977_0003_r_000000_0' done.\n",
      "2020-02-15 17:55:46,011 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1018724977_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406644\n",
      "\t\tFILE: Number of bytes written=36236543\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=105\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=394264576\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:55:46,011 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1018724977_0003_r_000000_0\n",
      "2020-02-15 17:55:46,011 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 17:55:50,910 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:50,911 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:50,912 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:50,961 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:50,973 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-15 17:55:51,031 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-15 17:55:51,033 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-15 17:55:51,046 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1310968655_0004\n",
      "2020-02-15 17:55:51,180 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789351088/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:51,188 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789351088/pig-0.17.0-core-h2.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:51,188 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789351088/pig-0.17.0-core-h2.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:51,188 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp-865680394/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1581789351088/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:51,190 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789351089/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:51,197 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789351089/automaton-1.11-8.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:51,197 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789351089/automaton-1.11-8.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:51,197 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp415133246/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1581789351089/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:51,199 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789351090/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:51,204 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789351090/antlr-runtime-3.4.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:51,204 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789351090/antlr-runtime-3.4.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:51,205 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp2029320210/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1581789351090/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:51,206 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1581789351091/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:51,212 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1581789351091/joda-time-2.9.3.jar /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-15 17:55:51,212 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1581789351091/joda-time-2.9.3.jar <- /datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:51,212 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp1243895233/tmp-2041828375/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1581789351091/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:51,285 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789351088/pig-0.17.0-core-h2.jar\n",
      "2020-02-15 17:55:51,285 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789351089/automaton-1.11-8.jar\n",
      "2020-02-15 17:55:51,285 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789351090/antlr-runtime-3.4.jar\n",
      "2020-02-15 17:55:51,285 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1581789351091/joda-time-2.9.3.jar\n",
      "2020-02-15 17:55:51,286 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-15 17:55:51,286 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-15 17:55:51,297 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-15 17:55:51,299 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-15 17:55:51,299 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-15 17:55:51,299 [Thread-130] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:51,299 [Thread-130] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:51,300 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-15 17:55:51,322 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-15 17:55:51,322 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1310968655_0004_m_000000_0\n",
      "2020-02-15 17:55:51,343 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:51,343 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:51,344 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:51,345 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 79\n",
      "Input split[0]:\n",
      "   Length = 79\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-15 17:55:51,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-15 17:55:51,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-15 17:55:51,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-15 17:55:51,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-15 17:55:51,363 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-15 17:55:51,364 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-15 17:55:51,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-15 17:55:51,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-15 17:55:51,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-15 17:55:51,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 89; bufvoid = 104857600\n",
      "2020-02-15 17:55:51,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2020-02-15 17:55:51,373 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-15 17:55:51,374 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1310968655_0004_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:51,386 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-15 17:55:51,387 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1310968655_0004_m_000000_0' done.\n",
      "2020-02-15 17:55:51,387 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1310968655_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23207997\n",
      "\t\tFILE: Number of bytes written=48315232\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=89\n",
      "\t\tMap output materialized bytes=105\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=398983168\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-15 17:55:51,388 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1310968655_0004_m_000000_0\n",
      "2020-02-15 17:55:51,388 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-15 17:55:51,392 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-15 17:55:51,392 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1310968655_0004_r_000000_0\n",
      "2020-02-15 17:55:51,425 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:51,425 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:51,429 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-15 17:55:51,429 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@30c6e4be\n",
      "2020-02-15 17:55:51,431 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-15 17:55:51,435 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1310968655_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-15 17:55:51,437 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local1310968655_0004_m_000000_0 decomp: 101 len: 105 to MEMORY\n",
      "2020-02-15 17:55:51,437 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 101 bytes from map-output for attempt_local1310968655_0004_m_000000_0\n",
      "2020-02-15 17:55:51,438 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->101\n",
      "2020-02-15 17:55:51,439 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-15 17:55:51,440 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:51,440 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-15 17:55:51,443 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:51,443 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-15 17:55:51,444 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 101 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-15 17:55:51,445 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 105 bytes from disk\n",
      "2020-02-15 17:55:51,445 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-15 17:55:51,445 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-15 17:55:51,445 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-15 17:55:51,446 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:51,449 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-15 17:55:51,449 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-15 17:55:51,571 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1310968655_0004_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-15 17:55:51,587 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-15 17:55:51,587 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1310968655_0004_r_000000_0 is allowed to commit now\n",
      "2020-02-15 17:55:51,623 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1310968655_0004_r_000000_0' to file:/datalake/AGD Lab/evaluacion-final-Farid1994/02-pig-50/q10-10/output/_temporary/0/task_local1310968655_0004_r_000000\n",
      "2020-02-15 17:55:51,627 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-15 17:55:51,627 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1310968655_0004_r_000000_0' done.\n",
      "2020-02-15 17:55:51,628 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1310968655_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23208239\n",
      "\t\tFILE: Number of bytes written=48315398\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=105\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=398983168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-15 17:55:51,629 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1310968655_0004_r_000000_0\n",
      "2020-02-15 17:55:51,629 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-15 17:55:56,516 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,518 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,519 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,537 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,538 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,539 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,545 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,547 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,548 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,555 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,556 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,557 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,563 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,564 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-15 17:55:56,565 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
